{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c79e59-b507-4399-90b7-bef181f5030d",
   "metadata": {},
   "source": [
    "# Using TensorFlow to train a neural network classifier on a dataset of enhancers in Drosophila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfb561-6b93-4702-ad7a-e5fe8b7100e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "pip install genomic-benchmarks\n",
    "pip install tensorflow-macos==2.12.0\n",
    "pip install tensorflow-addons\n",
    "pip install typing-extensions --upgrade  # fixing TF installation issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429e70a1-d717-4ed8-af04-8bc3e95fbe3d",
   "metadata": {},
   "source": [
    "## Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcace16f-6725-410f-b16b-7b0371baf6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dosorior/Python3.11/lib/python3.11/site-packages/genomic_benchmarks/utils/datasets.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/Users/dosorior/Python3.11/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/dosorior/Python3.11/lib/python3.11/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/Users/dosorior/Python3.11/lib/python3.11/site-packages/genomic_benchmarks/utils/datasets.py:50: UserWarning: No version specified. Using version 0.\n",
      "  warnings.warn(f\"No version specified. Using version {metadata['version']}.\")\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1D8u3m09CNIv8e4-5rOu5wKuwcLl1eejs\n",
      "From (redirected): https://drive.google.com/uc?id=1D8u3m09CNIv8e4-5rOu5wKuwcLl1eejs&confirm=t&uuid=c424ae1a-b6d0-42eb-a63d-90a49349b035\n",
      "To: /Users/dosorior/.genomic_benchmarks/drosophila_enhancers_stark.zip\n",
      "100%|██████████████████████████████████████| 6.34M/6.34M [00:01<00:00, 6.00MB/s]\n"
     ]
    }
   ],
   "source": [
    "#We will download the Drosophila enhancers dataset from https://github.com/\n",
    "#ML-Bioinfo-CEITEC/genomic_benchmarks/tree/main included in the publication by \n",
    "#Grešová, Katarína, et al. \"Genomic benchmarks: a collection of datasets for \n",
    "# genomic sequence classification.\" BMC Genomic Data 24.1 (2023): 25.\n",
    "\n",
    "#Importing the required libraries\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa \n",
    "import numpy as np\n",
    "\n",
    "from genomic_benchmarks.loc2seq import download_dataset\n",
    "from genomic_benchmarks.data_check import is_downloaded, info\n",
    "from genomic_benchmarks.models.tf import vectorize_layer\n",
    "from genomic_benchmarks.models.tf import get_basic_cnn_model_v0 as get_model\n",
    "\n",
    "if not is_downloaded('drosophila_enhancers_stark'):\n",
    "    download_dataset('drosophila_enhancers_stark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc24f53-cf06-428f-8ddb-ea22cf71d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset `drosophila_enhancers_stark` has 2 classes: negative, positive.\n",
      "\n",
      "The length of genomic intervals ranges from 236 to 3237, with average 2118.1238067688746 and median 2142.0.\n",
      "\n",
      "Totally 6914 sequences have been found, 5184 for training and 1730 for testing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>2592</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2592</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  test\n",
       "negative   2592   865\n",
       "positive   2592   865"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will take a look at the dataset\n",
    "info('drosophila_enhancers_stark', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db349f31-e15d-4ee5-b045-8d9c0c1588ff",
   "metadata": {},
   "source": [
    "## Creation of a TensorFlow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22257d61-3b5e-4cc5-8ae1-830dfca73c8b",
   "metadata": {},
   "source": [
    "We will create a TF Dataset to train the model. Because the directory structure of the dataset is ready for training, we can just call ```tf.keras.preprocessing.text_dataset_from_directory```function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c398643-727e-4c9e-ac54-4074ec1256ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5184 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "SEQ_PATH = Path.home() / '.genomic_benchmarks' / 'drosophila_enhancers_stark'\n",
    "#We will create two classes, corresponding to the positive and negative classes in the dataset\n",
    "CLASSES = [x.stem for x in (SEQ_PATH/'train').iterdir() if x.is_dir()]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "#Creation of the TF dataset\n",
    "train_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    SEQ_PATH / 'train',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_names=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ea00ae-ab18-47f7-b87c-2524f8b4a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES > 2:\n",
    "    train_dset = train_dset.map(lambda x, y: (x, tf.one_hot(y, depth=NUM_CLASSES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04a1de-3cab-498a-b001-db352f0c6d31",
   "metadata": {},
   "source": [
    "## Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c1b3b-2f26-4508-999f-ec475fe9c017",
   "metadata": {},
   "source": [
    "We will use TF ```TextVectorization``` layer and splitting to characters to convert the strings to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb74bb2e-c642-48a3-b96d-725cbb587fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 12:13:12.463995: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 't', 'a', 'c', 'g']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.adapt(train_dset.map(lambda x, y: x))\n",
    "VOCAB_SIZE = len(vectorize_layer.get_vocabulary())\n",
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786852ce-59f0-4a89-870c-0560c379a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text)-2, label\n",
    "\n",
    "train_ds = train_dset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d539b1-7b96-4fd4-93fc-94547c91184d",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c176e-9abb-463d-b0cb-e9e934bd057a",
   "metadata": {},
   "source": [
    "We will use a package with a simple convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce682b4-ffb8-4b77-ab02-ca06088af0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(NUM_CLASSES, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "765dba30-1721-4922-8309-6ae0caa3d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    # Loss function to minimize\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    # Optimizer\n",
    "    optimizer='adam',\n",
    "    # List of metrics to monitor\n",
    "    metrics=[tf.metrics.BinaryAccuracy(threshold=0.0), tfa.metrics.F1Score(name='f1',num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eddfc83-4f18-4d31-aa7f-7c2f70081304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "81/81 [==============================] - 5s 58ms/step - loss: 0.6872 - binary_accuracy: 0.5432 - f1: 0.6667\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 4s 55ms/step - loss: 0.6399 - binary_accuracy: 0.6350 - f1: 0.6667\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 4s 54ms/step - loss: 0.6080 - binary_accuracy: 0.6663 - f1: 0.6667\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 5s 61ms/step - loss: 0.5925 - binary_accuracy: 0.6807 - f1: 0.6667\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 5s 55ms/step - loss: 0.5823 - binary_accuracy: 0.6865 - f1: 0.6667\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 5s 56ms/step - loss: 0.5687 - binary_accuracy: 0.7020 - f1: 0.6667\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 5s 57ms/step - loss: 0.5670 - binary_accuracy: 0.6997 - f1: 0.6667\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 5s 59ms/step - loss: 0.5523 - binary_accuracy: 0.7170 - f1: 0.6667\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 5s 56ms/step - loss: 0.5581 - binary_accuracy: 0.7079 - f1: 0.6667\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 5s 58ms/step - loss: 0.5335 - binary_accuracy: 0.7280 - f1: 0.6667\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "EPOCHS = 10\n",
    "#Fit will train the model by slicing the data into \"batches\", and repeatedly iterating \n",
    "# over the entire dataset for a given number of epochs.\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95518f76-df16-4439-b3bb-2e4f99129804",
   "metadata": {},
   "source": [
    "The F1 score is the average of precision and recall. A perfect model would have a score of 1. The binary accuracy calculates how often predictions match binary labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b9c84-4650-4cfb-be79-311daa4df1f1",
   "metadata": {},
   "source": [
    "## Evaluation on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7c1b6-ca7a-40f4-a328-651b3f44f33b",
   "metadata": {},
   "source": [
    "Finally, we can do the same pre-processing for the test set and evaluate the F1 score of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b44c4e27-a802-4454-af38-d84cbd04b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1730 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dset = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    SEQ_PATH / 'test',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_names=CLASSES)\n",
    "\n",
    "if NUM_CLASSES > 2:\n",
    "    test_dset = test_dset.map(lambda x, y: (x, tf.one_hot(y, depth=NUM_CLASSES)))\n",
    "test_ds =  test_dset.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c8645d8-78c1-46cd-acfc-08dbb37daf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 15ms/step - loss: 0.7565 - binary_accuracy: 0.5289 - f1: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.756486713886261, 0.5289017558097839, array([0.6666667], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf42ee-47cb-42e3-9be5-f86b698e122b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
